{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-pfoCF6yehSx"
      },
      "source": [
        "# Herramienta de Privacidad: IBM AI Privacy 360 Toolkit\n",
        "\n",
        "## Introducción\n",
        "\n",
        "En este notebook, utilizaremos el IBM AI Privacy 360 Toolkit para evaluar y mejorar la privacidad de un modelo de IA entrenado en el dataset de Heart Disease.\n",
        "\n",
        "### Utilidad de IBM AI Privacy 360 Toolkit\n",
        "\n",
        "El IBM AI Privacy 360 Toolkit es una herramienta diseñada para ayudar a los desarrolladores y científicos de datos a abordar las preocupaciones de privacidad en los modelos de IA. Proporciona métodos y técnicas para evaluar y mitigar el riesgo de violaciones de privacidad en los datos y los modelos.\n",
        "\n",
        "El toolkit incluye funcionalidades para:\n",
        "\n",
        "*   Evaluación de riesgos de privacidad.\n",
        "*   Anonimización y agregación de datos.\n",
        "*   Modelado y mitigación de riesgos.\n",
        "*   Verificación de cumplimiento y auditoría.\n",
        "\n",
        "En este notebook, utilizaremos el toolkit para evaluar y mejorar la privacidad de un modelo de IA entrenado en el dataset de Heart Disease.\n",
        "\n",
        "### 1. Preparación del entorno\n",
        "\n",
        "Antes de comenzar, asegurémonos de tener instaladas las bibliotecas necesarias e importadas las librerías.\n",
        "\n",
        "Instalación de bibliotecas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrBJaLCsO8t9"
      },
      "outputs": [],
      "source": [
        "!pip install ai-privacy-toolkit\n",
        "!pip install adversarial-robustness-toolbox\n",
        "!pip install -U scikit-learn"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_Fuu64OXg7Ec"
      },
      "source": [
        "Importación de librerías:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7RbooJf6g6G5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ALUMNO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from art.estimators.classification.scikitlearn import ScikitlearnDecisionTreeClassifier\n",
        "from art.attacks.inference.attribute_inference import AttributeInferenceBlackBox"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KCmpvm39fviA"
      },
      "source": [
        "## 2. Carga del dataset\n",
        "\n",
        "Comenzaremos cargando el dataset de Heart Disease."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PalfER0VfyBa"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('../resources/HeartDiseaseDataset.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pCHW4t32gDoi"
      },
      "source": [
        "## 3. Preprocesamiento de los datos\n",
        "\n",
        "A continuación, dividiremos los datos en características (X) y etiquetas (y) y en conjuntos de entrenamiento y prueba. Tamibén realizaremos el preprocesamiento de los datos.\n",
        "\n",
        "División de los datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yt41JbLygCtp"
      },
      "outputs": [],
      "source": [
        "# División de los datos\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "L3v7-QzZhIyP"
      },
      "source": [
        "Preprocesamiento de los datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AyNaEKtFhKwl"
      },
      "outputs": [],
      "source": [
        "numeric_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca']\n",
        "\n",
        "preprocessor = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=0))])\n",
        "\n",
        "train_encoded = preprocessor.fit_transform(X_train)\n",
        "test_encoded = preprocessor.transform(X_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6mBSQ3T_hTos"
      },
      "source": [
        "## 4. Entrenamiento del modelo\n",
        "\n",
        "Ahora estamos listos para entrenar nuestro modelo utilizando un árbol de decisión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCS-w2qHhVmF",
        "outputId": "09246242-247c-4a20-e327-b59597f69331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión del modelo base: 0.819672131147541\n"
          ]
        }
      ],
      "source": [
        "model = DecisionTreeClassifier()\n",
        "model.fit(train_encoded, y_train)\n",
        "\n",
        "art_classifier = ScikitlearnDecisionTreeClassifier(model)\n",
        "\n",
        "base_model_accuracy = model.score(test_encoded, y_test)\n",
        "print('Precisión del modelo base:', base_model_accuracy)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HjJs9ehHhddC"
      },
      "source": [
        "## 5. Ataque de inferencia de atributos\n",
        "\n",
        "Finalmente, utilizaremos un ataque de inferencia de atributos para demostrar la importancia de proteger la privacidad de los datos sensibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEisg8oGhfuy",
        "outputId": "2cea8683-1b6d-4e17-ec3b-7c19bac6a2c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión del ataque de inferencia de atributos: 0.7143\n"
          ]
        }
      ],
      "source": [
        "# Característica de ataque después del preprocesamiento\n",
        "attack_feature = 1\n",
        "\n",
        "# Datos de entrenamiento sin la característica atacada\n",
        "x_train_for_attack = np.delete(train_encoded, attack_feature, 1)\n",
        "# Solo la característica atacada\n",
        "x_train_feature = train_encoded[:, attack_feature].copy().reshape(-1, 1)\n",
        "\n",
        "bb_attack = AttributeInferenceBlackBox(art_classifier, attack_feature=attack_feature)\n",
        "\n",
        "# Obtener predicciones del modelo original\n",
        "x_train_predictions = np.array([np.argmax(arr) for arr in art_classifier.predict(train_encoded)]).reshape(-1, 1)\n",
        "\n",
        "# Usar una porción del conjunto de entrenamiento para entrenar el ataque\n",
        "attack_train_ratio = 0.8\n",
        "attack_train_size = int(len(train_encoded) * attack_train_ratio)\n",
        "\n",
        "# Entrenar el modelo de ataque\n",
        "bb_attack.fit(train_encoded[:attack_train_size])\n",
        "\n",
        "# Obtener valores inferidos\n",
        "values = [0, 1]\n",
        "\n",
        "inferred_train_bb = bb_attack.infer(x_train_for_attack[attack_train_size:], pred=x_train_predictions[attack_train_size:], values=values)\n",
        "\n",
        "# Calcular precisión del ataque\n",
        "attack_acc = np.sum(inferred_train_bb == np.around(x_train_feature[attack_train_size:], decimals=8).reshape(1, -1)) / len(inferred_train_bb)\n",
        "print('Precisión del ataque de inferencia de atributos: {:.4f}'.format(attack_acc))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nMySg8DLke09"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "En este proyecto, hemos explorado el uso de IBM AI Privacy 360 para realizar un ataque de inferencia de atributos en un modelo de aprendizaje automático. A través de este proceso, hemos obtenido las siguientes conclusiones:\n",
        "\n",
        "*   La privacidad es un aspecto crítico en el desarrollo de modelos de aprendizaje automático. Es fundamental proteger la información sensible de los individuos y considerar la privacidad desde el inicio.\n",
        "\n",
        "*   Las técnicas de evaluación de privacidad, como el ataque de inferencia de atributos, nos permiten identificar las vulnerabilidades de privacidad en los modelos y evaluar su robustez frente a posibles ataques.\n",
        "\n",
        "En resumen, este proyecto nos ha permitido explorar la importancia de la privacidad en el aprendizaje automático y utilizar herramientas como IBM AI Privacy 360 para evaluar y mitigar los riesgos asociados. Al integrar consideraciones de privacidad desde el inicio y adoptar un enfoque proactivo para proteger la información sensible, podemos desarrollar modelos de aprendizaje automático más éticos y responsables."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
